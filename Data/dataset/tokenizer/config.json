{"architectures": ["BertForMaskedLM"],"model_type":"bert", "num_hidden_layers":4,"hidden_size":128,"intermediate_size":256,"max_position_embeddings":1536, "num_attention_heads":4, "vocab_size":25000}
